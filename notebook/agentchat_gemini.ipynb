{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67cee7e3",
   "metadata": {},
   "source": [
    "# Using Gemini in AutoGen with Other LLMs\n",
    "\n",
    "You don't need to handle OpenAI or Google's GenAI packages. AutoGen already handled all of these for you.\n",
    "\n",
    "You can just create different agents with different backend LLM with assistant agent, and all models/agents are at your fingertip.\n",
    "\n",
    "\n",
    "## Main Distinctions\n",
    "- Gemini does not have the \"system_message\" field (correct me if I am wrong). So, it's instruction following skills are not as strong as GPTs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d801d13b",
   "metadata": {},
   "source": [
    "Sample OAI_CONFIG_LIST \n",
    "\n",
    "```python\n",
    "[\n",
    "    {\n",
    "        \"model\": \"gpt-35-turbo\",\n",
    "        \"api_key\": \"your OpenAI Key goes here\",\n",
    "        \"base_url\": \"https://tnrllmproxy.azurewebsites.net/v1\",\n",
    "        \"api_version\": \"2023-06-01-preview\"\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"gpt-4-vision-preview\",\n",
    "        \"api_key\": \"your OpenAI Key goes here\",\n",
    "        \"api_version\": \"2023-06-01-preview\"\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"dalle\",\n",
    "        \"api_key\": \"your OpenAI Key goes here\",\n",
    "        \"api_version\": \"2023-06-01-preview\"\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"gemini-pro\",\n",
    "        \"api_key\": \"your Google's GenAI Key goes here\",\n",
    "        \"api_type\": \"google\"\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"gemini-pro-vision\",\n",
    "        \"api_key\": \"your Google's GenAI Key goes here\",\n",
    "        \"api_type\": \"google\"\n",
    "    }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fee066",
   "metadata": {},
   "source": [
    "### Before everything starts, install AutoGen with the `gemini` option\n",
    "```bash\n",
    "pip install \"pyautogen[gemini]~=0.2.0b4\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c37cd165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pdb\n",
    "import os\n",
    "import re\n",
    "\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Type, Union\n",
    "\n",
    "import autogen\n",
    "from autogen import AssistantAgent, Agent, UserProxyAgent, ConversableAgent\n",
    "\n",
    "from autogen.agentchat.contrib.img_utils import get_image_data, _to_pil\n",
    "from autogen.agentchat.contrib.multimodal_conversable_agent import MultimodalConversableAgent\n",
    "\n",
    "from termcolor import colored\n",
    "import random\n",
    "\n",
    "from autogen.code_utils import DEFAULT_MODEL, UNKNOWN, content_str, execute_code, extract_code, infer_lang\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cb2d08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ed6b642",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config_list_4v = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-4-vision-preview\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "config_list_gpt4 = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-4\", \"gpt-4-0314\", \"gpt4\", \"gpt-4-32k\", \"gpt-4-32k-0314\", \"gpt-4-32k-v0314\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "config_list_gemini = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gemini-pro\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "config_list_gemini_lmm = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gemini-pro-vision\"],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c3221e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cd4b59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d60857e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76f09481",
   "metadata": {},
   "source": [
    "## Gemini Assitant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53c6e552",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "Sort the array with Bubble Sort: [4, 1, 3, 2]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "```python\n",
      "# filename: bubble_sort.py\n",
      "def bubble_sort(arr):\n",
      "    n = len(arr)\n",
      "    for i in range(n):\n",
      "        for j in range(0, n-i-1):\n",
      "            if arr[j] > arr[j+1]:\n",
      "                arr[j], arr[j+1] = arr[j+1], arr[j]\n",
      "    return arr\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    arr = [4, 1, 3, 2]\n",
      "    print(\"Unsorted array: \", arr)\n",
      "    sorted_arr = bubble_sort(arr)\n",
      "    print(\"Sorted array: \", sorted_arr)\n",
      "```\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "Unsorted array:  [4, 1, 3, 2]\n",
      "Sorted array:  [1, 2, 3, 4]\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "assistant = AssistantAgent(\"assistant\", \n",
    "                           llm_config={\"config_list\": config_list_gemini, \"seed\": 42}, \n",
    "                           max_consecutive_auto_reply=3)\n",
    "# print(assistant.system_message)\n",
    "\n",
    "user_proxy = UserProxyAgent(\"user_proxy\", \n",
    "                            code_execution_config={\"work_dir\": \"coding\", \"use_docker\": False}, \n",
    "                            human_input_mode=\"NEVER\", \n",
    "                           is_termination_msg = lambda x: content_str(x.get(\"content\")).find(\"TERMINATE\") >= 0)\n",
    "\n",
    "user_proxy.initiate_chat(assistant, message=\"Sort the array with Bubble Sort: [4, 1, 3, 2]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de85984",
   "metadata": {},
   "source": [
    "## Agent Collaboration and Interactions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a2f2bb5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mGPT-4\u001b[0m (to Gemini-Pro):\n",
      "\n",
      "Do Transformers buy auto insurance or health insurance?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGemini-Pro\u001b[0m (to GPT-4):\n",
      "\n",
      "Transformers, being fictional robots, do not require auto or health insurance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGPT-4\u001b[0m (to Gemini-Pro):\n",
      "\n",
      "If Transformers were real and required insurance, would their coverage be a specialized form of property insurance instead of typical auto or health insurance?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGemini-Pro\u001b[0m (to GPT-4):\n",
      "\n",
      "Yes, if Transformers were real and required insurance, their coverage would likely be a specialized form of property insurance designed specifically for sentient robotic beings.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGPT-4\u001b[0m (to Gemini-Pro):\n",
      "\n",
      "Considering their dual nature as vehicles and sentient beings, could they potentially require a unique insurance policy that covers both aspects, merging elements of auto, health, and property insurance?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGemini-Pro\u001b[0m (to GPT-4):\n",
      "\n",
      "Yes, the unique nature of Transformers as both vehicles and sentient beings could necessitate a hybrid insurance policy that combines elements of auto, health, and property insurance to comprehensively cover their dual aspects.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGPT-4\u001b[0m (to Gemini-Pro):\n",
      "\n",
      "In a scenario where Transformers are integrated into human society, how would liability be determined in an accident involving a Transformer in vehicle formâ€”is the Transformer itself at fault, or would it be considered a driver error?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGemini-Pro\u001b[0m (to GPT-4):\n",
      "\n",
      "Liability in an accident involving a Transformer in vehicle form would depend on the specific circumstances, but could potentially be attributed to the Transformer itself if it was deemed to be acting autonomously, or to a human driver if they were controlling the Transformer at the time of the accident.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "gpt = AssistantAgent(\"GPT-4\", \n",
    "                     system_message=\"\"\"You should ask weird, tricky, and concise questions. \n",
    "Ask the next question based on (by evolving) the previous one.\"\"\",\n",
    "                       llm_config={\"config_list\": config_list_gpt4, \"seed\": 42}, \n",
    "                       max_consecutive_auto_reply=3)\n",
    "\n",
    "gemini = AssistantAgent(\"Gemini-Pro\", \n",
    "                     system_message=\"\"\"Always answer questions within one sentence. \"\"\",\n",
    "#                      system_message=\"answer:\",\n",
    "                       llm_config={\"config_list\": config_list_gemini, \"seed\": 42}, \n",
    "                       max_consecutive_auto_reply=4)\n",
    "\n",
    "\n",
    "\n",
    "gpt.initiate_chat(gemini, message=\"Do Transformers buy auto insurance or health insurance?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dbfb1c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mGPT-4\u001b[0m (to Gemini-Pro):\n",
      "\n",
      "Should Spider-Man invest in 401K?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGemini-Pro\u001b[0m (to GPT-4):\n",
      "\n",
      "Yes, Spider-Man should invest in a 401K to secure his financial future.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGPT-4\u001b[0m (to Gemini-Pro):\n",
      "\n",
      "Given Spider-Man's age and potential lifespan, what would be an appropriate asset allocation for his 401K?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGemini-Pro\u001b[0m (to GPT-4):\n",
      "\n",
      "An appropriate asset allocation for Spider-Man's 401K, given his age and potential lifespan, would be 80% stocks and 20% bonds.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGPT-4\u001b[0m (to Gemini-Pro):\n",
      "\n",
      "Considering Spider-Man's high-risk occupation, should he adjust this allocation to accommodate for potential periods of unemployment or disability?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGemini-Pro\u001b[0m (to GPT-4):\n",
      "\n",
      "Yes, Spider-Man should adjust his asset allocation to accommodate for potential periods of unemployment or disability, increasing his bond allocation to 30% to provide a more stable base of assets.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGPT-4\u001b[0m (to Gemini-Pro):\n",
      "\n",
      "Can Spider-Man's alter ego, as a freelance photographer, set up a Solo 401(k) to take advantage of higher contribution limits compared to an individual 401K?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGemini-Pro\u001b[0m (to GPT-4):\n",
      "\n",
      "Yes, Spider-Man's alter ego, as a freelance photographer, can set up a Solo 401(k) to take advantage of higher contribution limits compared to an individual 401K.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "gpt.initiate_chat(gemini, message=\"Should Spider-Man invest in 401K?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c079aa7",
   "metadata": {},
   "source": [
    "Let's switch position. Now, Gemini is the question raiser. \n",
    "\n",
    "This time, Gemini could not follow the system instruction well or evolve questions, because the Gemini does not handle system messages similar to GPTs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a1ead90",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mGemini-Pro\u001b[0m (to GPT-4):\n",
      "\n",
      "Do Transformers buy auto insurance or health insurance?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGPT-4\u001b[0m (to Gemini-Pro):\n",
      "\n",
      "Transformers are fictional robots, so they don't buy insurance, but if they did, they might need a special kind of insurance that combines aspects of both auto and health insurance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGemini-Pro\u001b[0m (to GPT-4):\n",
      "\n",
      "If the sun was a giant ball of cotton candy, would it be possible to eat it or would it melt too quickly?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGPT-4\u001b[0m (to Gemini-Pro):\n",
      "\n",
      "If the sun were a giant ball of cotton candy, it would not be possible to eat it because it would either disintegrate due to the vacuum of space or melt instantly from the residual heat.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGemini-Pro\u001b[0m (to GPT-4):\n",
      "\n",
      "If cats dreamt of being human, would they imagine themselves as hairless, bipedal beings or as giant, intelligent house cats?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGPT-4\u001b[0m (to Gemini-Pro):\n",
      "\n",
      "Cats might imagine themselves as giant, intelligent house cats since they would likely retain their feline perspective in their dreams.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGemini-Pro\u001b[0m (to GPT-4):\n",
      "\n",
      "If a group of people decided to create their own language, could they successfully keep it a secret from the rest of the world?\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "gpt = AssistantAgent(\"GPT-4\", \n",
    "                     system_message=\"\"\"Always answer questions within one sentence. \"\"\",\n",
    "                       llm_config={\"config_list\": config_list_gpt4, \"seed\": 42}, \n",
    "                       max_consecutive_auto_reply=3)\n",
    "\n",
    "gemini = AssistantAgent(\"Gemini-Pro\", \n",
    "                     system_message=\"\"\"You should ask weird, tricky, and concise questions. \n",
    "Ask the next question based on (by evolving) the previous one.\"\"\",\n",
    "                       llm_config={\"config_list\": config_list_gemini, \"seed\": 42}, \n",
    "                       max_consecutive_auto_reply=4)\n",
    "\n",
    "gemini.initiate_chat(gpt, message=\"Do Transformers buy auto insurance or health insurance?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ee10f29",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mGemini-Pro\u001b[0m (to GPT-4):\n",
      "\n",
      "Should Spider-Man invest in 401K?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGPT-4\u001b[0m (to Gemini-Pro):\n",
      "\n",
      "As a fictional character, Spider-Man does not require a 401(k), but his alter ego, if employed with such benefits, might consider it for retirement savings.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGemini-Pro\u001b[0m (to GPT-4):\n",
      "\n",
      "If the sun sneezes, does it become stars?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGPT-4\u001b[0m (to Gemini-Pro):\n",
      "\n",
      "No, a sneeze is a biological function that the sun, being a star, cannot perform.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGemini-Pro\u001b[0m (to GPT-4):\n",
      "\n",
      "If you could have any animal as your neighbor, who would it be and why a giraffe?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGPT-4\u001b[0m (to Gemini-Pro):\n",
      "\n",
      "A giraffe could be an interesting neighbor due to its unique height, allowing it to assist with tasks such as fetching items from tall trees or serving as a lookout.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGemini-Pro\u001b[0m (to GPT-4):\n",
      "\n",
      "If a cow decided to wear pants, what would be in its pockets?\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "gemini.initiate_chat(gpt, message=\"Should Spider-Man invest in 401K?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bf9c11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c35635e3",
   "metadata": {},
   "source": [
    "## Gemini RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd1ea1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee88e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9a21f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09139b42",
   "metadata": {},
   "source": [
    "## Gemini Multimodal\n",
    "\n",
    "You can create multimodal agent for Gemini the same way as the GPT-4V and LLaVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5098e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598c3d67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5fc7ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0d7ea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53b56419",
   "metadata": {},
   "source": [
    "## GPT  v.s. Gemini Arena\n",
    "\n",
    "Do you remember AutoGen can ask LLMs to play chess. Here, we create an arena to allow GPT and Gemini fight together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b18ca19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e47c9c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
